from langgraph.graph import StateGraph, END
from typing import TypedDict, Literal, List

from langchain_community.vectorstores import OpenSearchVectorSearch
from langchain_huggingface import HuggingFaceEmbeddings
from main import llm  # ê¸°ì¡´ì— ì •ì˜ëœ HuggingFacePipeline ë˜ëŠ” Groq ê¸°ë°˜ LLM

# âœ… ê²€ìƒ‰ ì „ìš©ìœ¼ë¡œ vectorstore ìƒì„±
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = OpenSearchVectorSearch(
    index_name="rag-index",
    embedding_function=embedding,
    opensearch_url="http://localhost:9200"
)

# ------------------------------
# âœ… ìƒíƒœ ì •ì˜
# ------------------------------
class RAGState(TypedDict):
    query: str
    docs: List[tuple]  # ë˜ëŠ” List[Tuple[Document, float]]
    reranked: List[dict]
    answer: str

# ğŸ” (1) Retrieval Node
def retrieve_node(state: RAGState) -> RAGState:
    docs_with_scores = vectorstore.similarity_search_with_score(state["query"], k=10)

    # âœ… score í¬í•¨ëœ íŠœí”Œë¡œ ì €ì¥
    return {**state, "docs": docs_with_scores}

# ğŸ§  (2) Rerank Node (ê°„ë‹¨ í•„í„° ë˜ëŠ” LLM rerank)
RERANK_PROMPT = """ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œì…ë‹ˆë‹¤.
ê° ë¬¸ì„œê°€ ì§ˆë¬¸ì— ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ì§€ [0.0 ~ 1.0] ì‚¬ì´ì˜ ì ìˆ˜ë¡œ í‰ê°€í•˜ì„¸ìš”.

ì§ˆë¬¸: "{query}"

ë¬¸ì„œ:
{doc}

ê´€ë ¨ë„ ì ìˆ˜ (ìˆ«ìë§Œ):"""
def rerank_node(state: RAGState) -> RAGState:
    scored = []

    for doc, score in state["docs"]:  # ê¸°ì¡´ ìœ ì‚¬ë„ scoreë„ í•¨ê»˜ ìˆìŒ
        prompt = RERANK_PROMPT.format(query=state["query"], doc=doc.page_content)

        try:
            response = llm.invoke(prompt)
            # LLM ì‘ë‹µì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ (ì˜ˆ: "0.9")
            rerank_score = float(response.strip())
        except Exception as e:
            print(f"âš ï¸ Rerank ì˜¤ë¥˜: {e}")
            rerank_score = 0.0

        scored.append({
            "content": doc.page_content,
            "original_score": score,
            "rerank_score": rerank_score
        })

    # ğŸ”¼ rerank_score ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    reranked = sorted(scored, key=lambda x: x["rerank_score"], reverse=True)[:2]
    return {**state, "reranked": reranked}

# âœï¸ (3) Answer Node
def answer_node(state: RAGState) -> RAGState:
    docs_text = "\n\n".join([
        f"[rerank_score={doc['rerank_score']:.2f}] {doc['content']}"
        for doc in state["reranked"]
    ])
    prompt = (
        "ì•„ë˜ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n\n"
        f"{docs_text}\n\n"
        f"ì§ˆë¬¸: {state['query']}\n"
        "ë‹µë³€:"
    )
    result = llm.invoke(prompt)
    return {**state, "answer": result}

# ------------------------------
# âœ… LangGraph êµ¬ì„±
# ------------------------------
builder = StateGraph(RAGState)

builder.add_node("retrieve", retrieve_node)
builder.add_node("rerank", rerank_node)
builder.add_node("generate_answer", answer_node)

builder.set_entry_point("retrieve")
builder.add_edge("retrieve", "rerank")
builder.add_edge("rerank", "generate_answer")
builder.add_edge("generate_answer", END)

rag_graph = builder.compile()

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    result = rag_graph.invoke({"query": "LLM ì— ëŒ€í•´ ì•Œë ¤ì£ "})
    print(f"ğŸ’¡ answer: '{result['answer']}'")
